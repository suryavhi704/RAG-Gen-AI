# 🧠 RAG-Based Text-to-Text Generation using LangChain

## 🔍 Overview
This project demonstrates an end-to-end implementation of Retrieval-Augmented Generation (RAG) for intelligent Q&A using LangChain, ChromaDB, and Gradio. The system retrieves contextual documents and generates human-like responses via a connected LLM pipeline.

## 📁 Project Structure
📦rag-langchain-project
├── data/ # Input documents
├── embeddings/ # Generated embedding vectors
├── vector_store/ # ChromaDB files
├── app.py # Gradio GUI and LangChain RAG integration
├── utils/ # Helper functions
└── README.md

## ⚙️ Technologies Used
- LangChain  
- ChromaDB  
- Hugging Face Transformers  
- Gradio  
- Python 3.10+  

## 🔁 Pipeline Steps
1. Data loading and pre-processing  
2. Embedding generation  
3. Vector storage using Chroma  
4. RAG chain linking with LLM  
5. GUI frontend via Gradio  

# 📸 Sample Output
User Input: "What is Ai?"
Response: "Ai has emerged as powerful engines  of innovation."

# 📚 Acknowledgments
This project was developed under the guidance of an IIT Indore expert as part of the Intellipaat AI and Data Science course.
